"""this is an EEGnet modification in terms to suit
    out task----predicting the seizure onset zone for
    focal epilepsy patients.
    we will make few modifications:
An EEGNet PyTorch version optimized for SOZ localization

Main modifications (optimized for your task):

1. Output layer: Changed to multi-label output (one SOZ probability per channel)

2. Feature dimensions: Adjusted according to your data (18 channels, 768 time points)

3. Added auxiliary task: Left and right brain classification to help learn spatial features

4. Added attention mechanism: Better focus on important channels and time points

5. Adjusted convolutional kernel size: Adapted to your sampling rate (typically 200Hz)"""

import os
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, accuracy_score


class SimpleEEGDataset(Dataset):
    def __init__(self, files):
        self.files = files
        # according bipolar_pairs to define right hemisphere（18 channels）
        # left brain: 0-3, 8-11 (8)
        # right brain: 4-7, 12-15 (8)
        # midline: 16-17 (2)

        self.channel_names = [
            'Fp1-F7',   # 0: 
            'F7-T3',    # 1: 
            'T3-T5',    # 2: 
            'T5-O1',    # 3: 
            'Fp2-F8',   # 4: 
            'F8-T4',    # 5: 
            'T4-T6',    # 6: 
            'T6-O2',    # 7: 
            'Fp1-F3',   # 8:
            'F3-C3',    # 9: 
            'C3-P3',    # 10: 
            'P3-O1',    # 11: 
            'Fp2-F4',   # 12: 
            'F4-C4',    # 13: 
            'C4-P4',    # 14: 
            'P4-O2',    # 15: 
            'Fz-Cz',    # 16: 
            'Cz-Pz'     # 17: 
        ]

        self.channel_hemispheres = torch.tensor([
            0, 0, 0, 0,  # 0-3: left temporal chain
            1, 1, 1, 1,  # 4-7: right temporal chain
            0, 0, 0, 0,  # 8-11: left parasagittal
            1, 1, 1, 1,  # 12-15: right parasagittal
            2, 2  # 16-17: midline
        ])

        print("channel-label match validation")
        for i, (name, hemi) in enumerate(zip(self.channel_names, self.channel_hemispheres)):
            hemisphere = ['left', 'right', 'midline'][int(hemi)]
            print(f"channel {i:2d}: {name:10s} → {hemisphere}")

    def _get_hemisphere_pseudo_label(self, soz_labels):
        """determine hemisphere based on soz label"""
        left_mask = self.channel_hemispheres == 0
        right_mask = self.channel_hemispheres == 1

        left_soz = torch.sum(soz_labels[left_mask]).item()
        right_soz = torch.sum(soz_labels[right_mask]).item()

        if left_soz + right_soz > 0:
            return 0 if left_soz >= right_soz else 1
        else:
            return 0 if random.random() < 0.55 else 1
    
    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        try:
            data = torch.load(self.files[idx])
        

            if idx < 5:  
                print(f"\nload data {idx}: {os.path.basename(self.files[idx])}")
                print(f"data type: {type(data)}")
                if isinstance(data, dict):
                    print(f"keys: {list(data.keys())}")
                    for key, value in data.items():
                        if torch.is_tensor(value):
                            print(f"  {key}: tensor, shape: {value.shape}")
                        else:
                            print(f"  {key}: {type(value)}, value: {str(value)[:50]}...")
        
            if torch.is_tensor(data):
                 eeg = data.float()
            elif isinstance(data, dict):
                eeg = None
                for key in ['eeg', 'data', 'signal', 'eeg_data', 'epoch']:
                    if key in data and torch.is_tensor(data[key]):
                        eeg = data[key].float()
                        break

                if eeg is None:
                    for key, value in data.items():
                        if torch.is_tensor(value):
                            eeg = value.float()
                            break
                
                    if eeg is None:
                        print(f"warning: can't find tensor {self.files[idx]} ")
                        eeg = torch.randn(1, 18, 4096).float()

            else:
                print(f"warning: file {self.files[idx]} is unknown format: {type(data)}")
                eeg = torch.randn(1, 18, 4096).float()

            if eeg.dim() == 2:
                eeg = eeg.unsqueeze(0)  # [18, 4096] -> [1, 18, 4096]
            elif eeg.dim() == 3:
                if eeg.shape[0] != 1:
                    eeg = eeg[:1, :, :]  
            else:
                raise ValueError(f"{eeg.dim()}")
            

            if eeg.shape[1] != 18:
                print(f"warning: file {self.files[idx]} only have {eeg.shape[1]} channels ")
            if eeg.shape[1] > 18:
                eeg = eeg[:, :18, :]
            else:
                padding = torch.zeros(1, 18 - eeg.shape[1], eeg.shape[2])
                eeg = torch.cat([eeg, padding], dim=1)

            soz_labels = torch.zeros(18).float()
            filename = os.path.basename(self.files[idx]).lower()

            if any(keyword in filename for keyword in ['spike', 'seizure', 'event']):
                n_abnormal = torch.randint(1, 4, (1,)).item()
                abnormal_channels = torch.randperm(18)[:n_abnormal]
                for ch in abnormal_channels:
                    soz_labels[ch] = 1.0

            left_channels = [0, 1, 2, 3, 8, 9, 10, 11]
            right_channels = [4, 5, 6, 7, 12, 13, 14, 15]
        
            left_soz = sum(soz_labels[ch] for ch in left_channels)
            right_soz = sum(soz_labels[ch] for ch in right_channels)
        
            if left_soz > right_soz:
                hemisphere_label = 0
            elif right_soz > left_soz:
                hemisphere_label = 1
            else:
                hemisphere_label = torch.randint(0, 2, (1,)).item()
        
            return eeg, soz_labels, hemisphere_label
        
        except Exception as e:
            print(f"load error {self.files[idx]}: {e}")
            return (torch.randn(1, 18, 4096), 
                    torch.zeros(18).float(), 
                    torch.randint(0, 2, (1,)).item())


    def get_dataloaders():
        data_root = "/home/sv25/Desktop/eeg_epochs_output"
        all_pt_files = []

        if not os.path.exists(data_root):
            print(f"path error: {data_root}")
            return None, None
    
        import glob
        search_pattern = os.path.join(data_root, "**/*.pt")
        all_pt_files = glob.glob(search_pattern, recursive=True)

        if not all_pt_files:
            print(f"no .pt file")
            return None, None
        print(f"found {len(all_pt_files)} .pt files")

        if len(all_pt_files) > max_samples:
            selected_files = random.sample(all_pt_files, max_samples)
            print(f"randomly choose {max_samples} files")
        else:
            selected_files = all_pt_files
            print(f"files been selected {len(selected_files)}")

        random.shuffle(selected_files)
        split_idx = int(0.8 * len(selected_files))
        train_files = selected_files[:split_idx]
        val_files = selected_files[split_idx:]
    
        print(f"training sets has: {len(train_files)} samples")
        print(f"validation sets has: {len(val_files)} samples")

        train_dataset = SimpleEEGDataset(train_files)
        val_dataset = SimpleEEGDataset(val_files)

        num_workers = min(4, os.cpu_count() // 2)  
        print(f"used {num_workers} worker")

        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,  
            persistent_workers=True if num_workers > 0 else False,  
            prefetch_factor=2 if num_workers > 0 else None  
        )
    
        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True,
            persistent_workers=True if num_workers > 0 else False
        )
    
        return train_loader, val_loader


class SOZHead(nn.Module):
    def __init__(self, input_dim, num_channels):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, num_channels)

        self.channel_interaction = nn.Parameter(torch.eye(num_channels) * 0.1)
        self.elu = nn.ELU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        residual = x

        x = self.elu(self.fc1(x))
        x = self.dropout(x)
        x = self.elu(self.fc2(x))
        x = self.dropout(x)

        if residual.shape[1] >= 128:
            x = x + residual[:, :128]
        else:
            x = x + residual

        soz_logits = self.fc3(x)
        soz_logits = soz_logits @ self.channel_interaction

        return torch.sigmoid(soz_logits)


class FrequencyAttention(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.freq_pool = nn.AdaptiveAvgPool2d((None, 1))
        self.attention = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 8, 1),
            nn.ELU(),
            nn.Conv2d(in_channels // 8, in_channels, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        freq_weights = self.freq_pool(x)
        freq_weights = self.attention(freq_weights)
        return x * freq_weights


class AdaptiveNormalization(nn.Module):
    def __init__(self, num_channels):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(1, 1, num_channels, 1))
        self.beta = nn.Parameter(torch.zeros(1, 1, num_channels, 1))

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)
        std = x.std(dim=-1, keepdim=True) + 1e-5
        x_normalized = (x - mean) / std
        return x_normalized * self.gamma + self.beta


class EEGNetSOZ(nn.Module):
    def __init__(self, nb_classes=2, Chans=18, Samples=4096,
                 dropoutRate=0.3, kernLength=128, F1=8, D=2, F2=16,
                 dropoutType='Dropout', soz_channels=18):
        super(EEGNetSOZ, self).__init__()

        self.Chans = Chans
        self.Samples = Samples
        self.soz_channels = soz_channels
        self.F1 = F1
        self.D = D
        self.F2 = F2

        # multi size kernel
        self.conv1_short = nn.Conv2d(1, F1 // 2, (1, 64), padding=(0, 32))
        self.conv1_long = nn.Conv2d(1, F1 // 2, (1, 256), padding=(0, 128))
        self.conv1_merge = nn.Conv2d(F1, F1, (1, 1))
        self.batchnorm1 = nn.BatchNorm2d(F1)

        # spatial filter
        self.depthwise = nn.Conv2d(
            F1, F1 * D, (Chans, 1),
            groups=F1,
            bias=False
        )
        self.batchnorm2 = nn.BatchNorm2d(F1 * D)
        self.activation1 = nn.ELU()

        # pooling
        self.pool1 = nn.Sequential(
            nn.AvgPool2d((1, 2)),
            nn.Conv2d(F1 * D, F1 * D, (1, 3), stride=(1, 2), padding=(0, 1))
        )

        # freq attention
        self.freq_attention = FrequencyAttention(F1 * D)

        if dropoutType == 'SpatialDropout2D':
            self.dropout1 = nn.Dropout2d(dropoutRate)
        else:
            self.dropout1 = nn.Dropout(dropoutRate)

        # separable depthwise convolution
        self.separable_depthwise = nn.Conv2d(
            F1 * D, F1 * D, (1, 16),
            padding=(0, 8),
            groups=F1 * D,
            bias=False
        )
        self.separable_pointwise = nn.Conv2d(
            F1 * D, F2, (1, 1),
            bias=False
        )
        self.batchnorm3 = nn.BatchNorm2d(F2)
        self.activation2 = nn.ELU()

        # pooling2
        self.pool2 = nn.Sequential(
            nn.MaxPool2d((1, 4)),
            nn.Dropout2d(0.3)
        )
        self.dropout2 = nn.Dropout(dropoutRate)

        self.time_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, None)),
            nn.Conv2d(F2, F2 // 4, 1),
            nn.ELU(),
            nn.Conv2d(F2 // 4, F2, 1),
            nn.Sigmoid()
        )

        self.adaptive_norm = AdaptiveNormalization(Chans)
        self._calculate_flatten_dim()
        self.soz_head = SOZHead(self.flatten_dim, soz_channels)

        self.hemisphere_head = nn.Sequential(
            nn.Linear(self.flatten_dim, 64),
            nn.ELU(),
            nn.Linear(64, 2)
        )

        self._initialize_weights()

    def _calculate_flatten_dim(self):
        with torch.no_grad():
            x = torch.randn(1, 1, self.Chans, self.Samples)

            x_short = self.conv1_short(x)
            x_long = self.conv1_long(x)
            x = torch.cat([x_short, x_long], dim=1)
            x = self.conv1_merge(x)

            x = self.depthwise(x)
            x = self.pool1[0](x)
            x = self.pool1[1](x)

            x = self.separable_depthwise(x)
            x = self.separable_pointwise(x)
            x = self.pool2[0](x)

            self.flatten_dim = x.numel()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x, return_features=False):
        if x.dim() == 3:
            x = x.unsqueeze(1)

        x = self.adaptive_norm(x)

        x_short = self.conv1_short(x)
        x_long = self.conv1_long(x)
        x = torch.cat([x_short, x_long], dim=1)
        x = self.conv1_merge(x)
        x = self.batchnorm1(x)

        x = self.depthwise(x)
        x = self.batchnorm2(x)
        x = self.activation1(x)

        x = self.pool1(x)
        x = self.freq_attention(x)
        x = self.dropout1(x)

        mid_features = x.clone() if return_features else None

        x = self.separable_depthwise(x)
        x = self.separable_pointwise(x)
        x = self.batchnorm3(x)
        x = self.activation2(x)

        attention_weights = self.time_attention(x)
        x = x * attention_weights

        x = self.pool2(x)
        x = self.dropout2(x)

        x = x.view(x.size(0), -1)

        soz_pred = self.soz_head(x)
        hemisphere_pred = self.hemisphere_head(x)

        if return_features:
            return soz_pred, hemisphere_pred, mid_features
        else:
            return soz_pred, hemisphere_pred


def quick_test_model():
    """quick model structure test"""
    batch_size = 4
    test_input = torch.randn(batch_size, 1, 18, 4096)
    model = EEGNetSOZ(Chans=18, Samples=4096)

    soz_pred, hemisphere_pred = model(test_input)

    print(f"input shape: {test_input.shape}")
    print(f"SOZ prediction shape: {soz_pred.shape}")
    print(f"hemisphere prediction shaape: {hemisphere_pred.shape}")

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"total parameters: {total_params:,}")
    print(f"trainable parameters: {trainable_params:,}")

    return model


def train_model(model, train_loader, val_loader, epochs=10, learning_rate=1e-3):
    """training model"""
    criterion_soz = nn.BCELoss()
    criterion_hemi = nn.CrossEntropyLoss()

    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    history = {
        'train_loss': [],
        'val_loss': [],
        'train_soz_auc': [],
        'val_soz_auc': [],
        'train_hemi_acc': [],
        'val_hemi_acc': []
    }

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    print(f"device: {device}")

    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        train_soz_preds = []
        train_soz_labels = []
        train_hemi_preds = []
        train_hemi_labels = []

        for batch_idx, (eeg_data, soz_labels, hemisphere_labels) in enumerate(train_loader):
            eeg_data = eeg_data.to(device)
            soz_labels = soz_labels.to(device)
            hemisphere_labels = hemisphere_labels.to(device)

            optimizer.zero_grad()

            soz_pred, hemi_pred = model(eeg_data)

            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels)
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            train_loss += total_loss.item()
            train_soz_preds.append(soz_pred.detach().cpu())
            train_soz_labels.append(soz_labels.detach().cpu())
            train_hemi_preds.append(hemi_pred.detach().argmax(dim=1).cpu())
            train_hemi_labels.append(hemisphere_labels.detach().cpu())

            if batch_idx % 10 == 0:
                print(
                    f'Epoch {epoch + 1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | Loss: {total_loss.item():.4f}')

        train_loss /= len(train_loader)
        train_soz_preds = torch.cat(train_soz_preds)
        train_soz_labels = torch.cat(train_soz_labels)
        train_hemi_preds = torch.cat(train_hemi_preds)
        train_hemi_labels = torch.cat(train_hemi_labels)

        # validation
        val_loss, val_soz_auc, val_hemi_acc = validate_model(model, val_loader, criterion_soz, criterion_hemi, device)

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_soz_auc'].append(val_soz_auc)
        history['val_hemi_acc'].append(val_hemi_acc)

        scheduler.step()

        print(f'\nEpoch {epoch + 1}/{epochs}:')
        print(f'train loss: {train_loss:.4f}')
        print(f'validate loss: {val_loss:.4f}')
        print(f'validate SOZ AUC: {val_soz_auc:.4f}')
        print(f'validation hemisphere prediction accuracy: {val_hemi_acc:.4f}')
        print('-' * 50)

    return model, history


def validate_model(model, val_loader, criterion_soz, criterion_hemi, device):
    """model validation"""
    model.eval()
    val_loss = 0.0
    all_soz_preds = []
    all_soz_labels = []
    all_hemi_preds = []
    all_hemi_labels = []

    with torch.no_grad():
        for eeg_data, soz_labels, hemisphere_labels in val_loader:  
            eeg_data = eeg_data.to(device)
            soz_labels = soz_labels.to(device)
            hemisphere_labels = hemisphere_labels.to(device)

            soz_pred, hemi_pred = model(eeg_data)

            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels)
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            val_loss += total_loss.item()

            all_soz_preds.append(soz_pred.cpu())
            all_soz_labels.append(soz_labels.cpu())
            all_hemi_preds.append(hemi_pred.argmax(dim=1).cpu())
            all_hemi_labels.append(hemisphere_labels.cpu())

    val_loss /= len(val_loader)

    # caculate SOZ AUC
    all_soz_preds = torch.cat(all_soz_preds).numpy()
    all_soz_labels = torch.cat(all_soz_labels).numpy()

    channel_aucs = []
    for ch in range(all_soz_preds.shape[1]):
        try:
            auc = roc_auc_score(all_soz_labels[:, ch], all_soz_preds[:, ch])
            channel_aucs.append(auc)
        except:
            channel_aucs.append(0.5)

    soz_auc = np.mean(channel_aucs)

    # caculate hemisphere prediction accuracy
    all_hemi_preds = torch.cat(all_hemi_preds).numpy()
    all_hemi_labels = torch.cat(all_hemi_labels).numpy()
    hemi_acc = accuracy_score(all_hemi_labels, all_hemi_preds)

    return val_loss, soz_auc, hemi_acc


def plot_training_history(history):
    """plotting training history"""
    epochs = range(1, len(history['train_loss']) + 1)

    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 2)
    plt.plot(epochs, history['val_soz_auc'], 'g-', label='SOZ AUC')
    plt.xlabel('Epoch')
    plt.ylabel('AUC')
    plt.title('SOZ Prediction AUC')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim([0.4, 1.0])

    plt.subplot(1, 3, 3)
    plt.plot(epochs, history['val_hemi_acc'], 'm-', label='Hemisphere Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Hemisphere Classification Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim([0.4, 1.0])

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
    plt.show()


def predict_soz_and_hemisphere(model, eeg_input, threshold=0.5):
    """predict SOZ channel and hemisphere"""
    model.eval()
    device = next(model.parameters()).device

    with torch.no_grad():
        if eeg_input.dim() == 3:
            eeg_input = eeg_input.unsqueeze(0)
        eeg_input = eeg_input.to(device)

        soz_pred, hemi_pred = model(eeg_input)

    soz_probs = soz_pred.squeeze().cpu().numpy()
    soz_channels = np.where(soz_probs > threshold)[0].tolist()

    hemisphere_probs = torch.softmax(hemi_pred, dim=1).squeeze().cpu().numpy()
    predicted_hemisphere = 0 if hemisphere_probs[0] > hemisphere_probs[1] else 1

    # channel in groups
    left_channels = [0, 1, 2, 3, 8, 9, 10, 11]
    right_channels = [4, 5, 6, 7, 12, 13, 14, 15]

    left_soz = [ch for ch in soz_channels if ch in left_channels]
    right_soz = [ch for ch in soz_channels if ch in right_channels]

    # dominant hemisphere
    if len(left_soz) > len(right_soz):
        dominant_hemisphere = "Left"
    elif len(right_soz) > len(left_soz):
        dominant_hemisphere = "Right"
    else:
        dominant_hemisphere = "Bilateral"

    # channel loc
    channel_names = [
        'Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1',  # 0-3
        'Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2',  # 4-7
        'Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1',  # 8-11
        'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2',  # 12-15
        'Fz-Cz', 'Cz-Pz'  # 16-17
    ]

    result = {
        'soz_channels': soz_channels,
        'soz_channel_names': [channel_names[ch] for ch in soz_channels],
        'soz_probabilities': soz_probs.tolist(),
        'predicted_hemisphere': 'Left' if predicted_hemisphere == 0 else 'Right',
        'hemisphere_probabilities': hemisphere_probs.tolist(),
        'left_soz_channels': left_soz,
        'right_soz_channels': right_soz,
        'dominant_hemisphere': dominant_hemisphere,
        'detailed_info': f"SOZ in{dominant_hemisphere}hemisphere，channel: {[channel_names[ch] for ch in soz_channels]}"
    }

    return result


if __name__ == "__main__":
    print("quick test for model")
    model = quick_test_model()

    print("\n obtained data loader")
    train_loader, val_loader = get_dataloaders()

    if train_loader is None or val_loader is None:
        print("failed to load data")
        exit(1)

    print("\n starts training")
    print(f"training batch: {len(train_loader)}")
    print(f"validation batch: {len(val_loader)}")

    trained_model, history = train_model(
        model,
        train_loader,
        val_loader,
        epochs=10,
        learning_rate=1e-3
    )

    print("\n plotting training history")
    plot_training_history(history)

    # save model
    torch.save(trained_model.state_dict(), 'eegnet_soz_model.pth')
    print("model saved as 'eegnet_soz_model.pth'")

    # prediction test after training
    print("\n test model after training")
    test_eeg = torch.randn(1, 1, 18, 4096)
    result = predict_soz_and_hemisphere(trained_model, test_eeg)
    print(f"prediction: {result['detailed_info']}")
    print(f"SOZ probability: {result['soz_probabilities']}")
    print(f"hemisphere probability: {result['hemisphere_probabilities']}")
