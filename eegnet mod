"""this is an EEGnet modification in terms to suit
    out task----predicting the seizure onset zone for
    focal epilepsy patients.
    we will make few modifications:
An EEGNet PyTorch version optimized for SOZ localization

Main modifications (optimized for your task):

1. Output layer: Changed to multi-label output (one SOZ probability per channel)

2. Feature dimensions: Adjusted according to your data (18 channels, 768 time points)

3. Added auxiliary task: Left and right brain classification to help learn spatial features

4. Added attention mechanism: Better focus on important channels and time points

5. Adjusted convolutional kernel size: Adapted to your sampling rate (typically 200Hz)"""



import os, random
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.utils.data import Dataset, DataLoader


#### data loading
class SimpleEEGDataset(Dataset):
    def __init__(self, files):
        self.files = files
        # 为每个通道定义确切的大脑半球（0=左，1=右，2=中线）
        # 这是基于标准10-20系统的longitudinal bipolar montage
        self.channel_hemispheres = torch.tensor([
            0, 0, 0, 0,  # FP1-F7, F7-T3, T3-T5, T5-O1 (左脑)
            1, 1, 1, 1,  # FP2-F8, F8-T4, T4-T6, T6-O2 (右脑)
            2, 2,  # FZ-CZ, CZ-PZ (中线)
            0, 0, 1, 1,  # T3-C3, C3-CZ, CZ-C4, C4-T4 (左右交叉，但可归类)
            0, 0, 0, 0,  # FP1-F3, F3-C3, C3-P3, P3-O1 (左脑)
        ])

    def __getitem__(self, idx):
        data = torch.load(self.files[idx])
        eeg = data['eeg'].float().unsqueeze(0)
        soz_labels = data['soz_labels'].float() if 'soz_labels' in data else torch.zeros(18)

        # 方法1：基于电极位置生成伪标签
        hemisphere_label = self._get_hemisphere_pseudo_label(soz_labels)

        return eeg, soz_labels, hemisphere_label

    def _get_hemisphere_pseudo_label(self, soz_labels):
        left_mask = self.channel_hemispheres == 0
        right_mask = self.channel_hemispheres == 1

        left_soz = torch.sum(soz_labels[left_mask]).item()
        right_soz = torch.sum(soz_labels[right_mask]).item()

        if left_soz + right_soz > 0:
            return 0 if left_soz >= right_soz else 1
        else:
            return random.choices([0, 1], weights=[0.55, 0.45])[0]  # 轻微偏左



def get_dataloaders():
    data_root = "/home/sv25/desktop/eeg_epochs_output"
    all_pt_files = []

    for patient_id in os.listdir(data_root):
        patient_path = os.path.join(data_root, patient_id)
        if not os.path.isdir(patient_path):
            continue

        for sess_dir in os.listdir(patient_path):
            session_path = os.path.join(patient_path, session_dir)
            all_pt_files.append(file_path)

    print(f"numbers of file has been found{len(all_pt_files)}")

    max_files = 10000
    if len(all_pt_files) > max_files:
        selected_files = random.sample(all_pt_files, max_files)
    else:
        selected_files = all_pt_files
        print(f"warning: there are not enopugh files has been extracted, only {len(all_pt_files)}has been extracted")

    split = (int(0.8) * len(selected_files))
    train_files = selected_files[:split]
    val_files = selected_files[:split]

    print(f"training samples: {len(train_files)}")
    print(f"validation files{len(val_files)}")

    ##dataloader

    train_loader = DataLoader(SimpleEEGDataset(train_files), batch_size=100, shuffle=True)
    val_loader = DataLoader(SimpleEEGDataset(val_files), batch_size=100, shuffle=False)
    return train_loader, val_loader


class SOZHead(nn.Module):
    def __init__(self, input_dim, num_channels):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, num_channels)

        self.channel_interaction = nn.Parameter(torch.eye(num_channels) * 0.1)
        self.elu = nn.ELU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        residual = x

        x = self.elu(self.fc1(x))
        x = self.dropout(x)
        x = self.elu(self.fc2(x))
        x = self.dropout(x)

        if residual.shape[1] >= 128:
            x = x + residual[:, :128]
        else:
            x = x + residual

        soz_logits = self.fc3(x)
        soz_logits = soz_logits @ self.channel_interaction

        return torch.sigmoid(soz_logits)


class FrequencyAttention(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.freq_pool = nn.AdaptiveAvgPool2d((None, 1))
        self.attention = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 8, 1),
            nn.ELU(),
            nn.Conv2d(in_channels // 8, in_channels, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        freq_weights = self.freq_pool(x)
        freq_weights = self.attention(freq_weights)
        return x * freq_weights


class AdaptiveNormalization(nn.Module):
    def __init__(self, num_channels):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(1, 1, num_channels, 1))
        self.beta = nn.Parameter(torch.zeros(1, 1, num_channels, 1))

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)
        std = x.std(dim=-1, keepdim=True) + 1e-5
        x_normalized = (x - mean) / std
        return x_normalized * self.gamma + self.beta


class EEGNetSOZ(nn.Module):
    def __init__(self, nb_classes=2, Chans=18, Samples=4096,
                 dropoutRate=0.3, kernLength=128, F1=8, D=2, F2=16,
                 dropoutType='Dropout', soz_channels=18):
        super(EEGNetSOZ, self).__init__()

        self.Chans = Chans
        self.Samples = Samples
        self.soz_channels = soz_channels
        self.F1 = F1
        self.D = D
        self.F2 = F2

        # multi size kernal (mod)
        self.conv1_short = nn.Conv2d(1, F1 // 2, (1, 64), padding=(0, 32))
        self.conv1_long = nn.Conv2d(1, F1 // 2, (1, 256), padding=(0, 128))
        self.conv1_merge = nn.Conv2d(F1, F1, (1, 1))
        self.batchnorm1 = nn.BatchNorm2d(F1)

        # spatial filter (mod)
        self.depthwise = nn.Conv2d(
            F1, F1 * D, (Chans, 1),
            groups=F1,
            bias=False
        )
        self.batchnorm2 = nn.BatchNorm2d(F1 * D)
        self.activation1 = nn.ELU()

        # pooling (mod)
        self.pool1 = nn.Sequential(
            nn.AvgPool2d((1, 2)),
            nn.Conv2d(F1 * D, F1 * D, (1, 3), stride=(1, 2), padding=(0, 1))
        )

        # freq attention (mod)
        self.freq_attention = FrequencyAttention(F1 * D)

        if dropoutType == 'SpatialDropout2D':
            self.dropout1 = nn.Dropout2d(dropoutRate)
        else:
            self.dropout1 = nn.Dropout(dropoutRate)

        # separable depthwise convolution (mod)
        self.separable_depthwise = nn.Conv2d(
            F1 * D, F1 * D, (1, 16),
            padding=(0, 8),
            groups=F1 * D,
            bias=False
        )
        self.separable_pointwise = nn.Conv2d(
            F1 * D, F2, (1, 1),
            bias=False
        )
        self.batchnorm3 = nn.BatchNorm2d(F2)
        self.activation2 = nn.ELU()

        # polling2 (mod)
        self.pool2 = nn.Sequential(
            nn.MaxPool2d((1, 4)),
            nn.Dropout2d(0.3)
        )
        self.dropout2 = nn.Dropout(dropoutRate)

        self.time_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, None)),
            nn.Conv2d(F2, F2 // 4, 1),
            nn.ELU(),
            nn.Conv2d(F2 // 4, F2, 1),
            nn.Sigmoid()
        )

        self.adaptive_norm = AdaptiveNormalization(Chans)  # normalization
        self._calculate_flatten_dim()  # flatten the matrix
        self.soz_head = SOZHead(self.flatten_dim, soz_channels)  # output layer

        self.hemisphere_head = nn.Sequential(
            nn.Linear(self.flatten_dim, 64),
            nn.ELU(),
            nn.Linear(64, 2)
        )

        self._initialize_weights()

    def _calculate_flatten_dim(self):
        with torch.no_grad():
            x = torch.randn(1, 1, self.Chans, self.Samples)

            x_short = self.conv1_short(x)
            x_long = self.conv1_long(x)
            x = torch.cat([x_short, x_long], dim=1)
            x = self.conv1_merge(x)

            x = self.depthwise(x)
            x = self.pool1[0](x)
            x = self.pool1[1](x)

            x = self.separable_depthwise(x)
            x = self.separable_pointwise(x)
            x = self.pool2[0](x)  # MaxPool

            self.flatten_dim = x.numel()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x, return_features=False):
        if x.dim() == 3:
            x = x.unsqueeze(1)

        x = self.adaptive_norm(x)

        x_short = self.conv1_short(x)
        x_long = self.conv1_long(x)
        x = torch.cat([x_short, x_long], dim=1)
        x = self.conv1_merge(x)
        x = self.batchnorm1(x)

        x = self.depthwise(x)
        x = self.batchnorm2(x)
        x = self.activation1(x)

        x = self.pool1(x)
        x = self.freq_attention(x)
        x = self.dropout1(x)

        mid_features = x.clone() if return_features else None

        x = self.separable_depthwise(x)
        x = self.separable_pointwise(x)
        x = self.batchnorm3(x)
        x = self.activation2(x)

        attention_weights = self.time_attention(x)
        x = x * attention_weights

        x = self.pool2(x)
        x = self.dropout2(x)

        x = x.view(x.size(0), -1)

        soz_pred = self.soz_head(x)
        hemisphere_pred = self.hemisphere_head(x)

        if return_features:
            return soz_pred, hemisphere_pred, mid_features
        else:
            return soz_pred, hemisphere_pred


def quick_test_model():
    batch_size = 4
    test_input = torch.randn(batch_size, 1, 18, 4096)
    model = EEGNetSOZ(Chans=18, Samples=4096)

    soz_pred, hemisphere_pred = model(test_input)

    print(f"input shaope: {test_input.shape}")
    print(f"soz predict shape: {soz_pred.shape}")
    print(f"hemisphere shape: {hemisphere_pred.shape}")

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"total parameters: {total_params:,}")
    print(f"trainable parameters: {trainable_params:,}")

    return model


if __name__ == "__main__":
    print("=== quick_test_model ===")
    model = quick_test_model()

    print("\n=== model structure ===")
    print(model)


import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, accuracy_score


def train_model(model, train_loader, val_loader, epochs=50, learning_rate=1e-3):
    """model training"""
    # 1. define loss function
    criterion_soz = nn.BCELoss()  # binary for soz pred
    criterion_hemi = nn.CrossEntropyLoss()  # hemi is multi classification

    # 2. optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)

    # 3. adjust LR
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    # 4. history
    history = {
        'train_loss': [],
        'val_loss': [],
        'train_soz_auc': [],
        'val_soz_auc': [],
        'train_hemi_acc': [],
        'val_hemi_acc': []
    }

    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        train_soz_preds = []
        train_soz_labels = []
        train_hemi_preds = []
        train_hemi_labels = []

        for batch_idx, (eeg_data, soz_labels) in enumerate(train_loader):
            optimizer.zero_grad()

            # forward
            soz_pred, hemi_pred = model(eeg_data)


            batch_size = eeg_data.size(0)
            hemisphere_labels = torch.randint(0, 2, (batch_size,))

            # loss caculation
            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels)

            # combined loss
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            # backward prop
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # documentation
            train_loss += total_loss.item()
            train_soz_preds.append(soz_pred.detach())
            train_soz_labels.append(soz_labels.detach())
            train_hemi_preds.append(hemi_pred.detach().argmax(dim=1))
            train_hemi_labels.append(hemisphere_labels.detach())

            if batch_idx % 10 == 0:
                print(f'Epoch {epoch+1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | Loss: {total_loss.item():.4f}')

        train_loss /= len(train_loader)
        train_soz_preds = torch.cat(train_soz_preds)
        train_soz_labels = torch.cat(train_soz_labels)
        train_hemi_preds = torch.cat(train_hemi_preds)
        train_hemi_labels = torch.cat(train_hemi_labels)

        # validation
        val_loss, val_soz_auc, val_hemi_acc = validate_model(model, val_loader, criterion_soz, criterion_hemi)

        # history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_soz_auc'].append(val_soz_auc)
        history['val_hemi_acc'].append(val_hemi_acc)

        # renew LR
        scheduler.step()

        print(f'\nEpoch {epoch + 1}/{epochs}:')
        print(f'  Train Loss: {train_loss:.4f}')
        print(f'  Val Loss: {val_loss:.4f}')
        print(f'  Val SOZ AUC: {val_soz_auc:.4f}')
        print(f'  Val Hemisphere Acc: {val_hemi_acc:.4f}')
        print('-' * 50)

    return model, history


def validate_model(model, val_loader, criterion_soz, criterion_hemi):
    """validation model"""
    model.eval()
    val_loss = 0.0
    all_soz_preds = []
    all_soz_labels = []
    all_hemi_preds = []
    all_hemi_labels = []

    with torch.no_grad():
        for eeg_data, soz_labels in val_loader:
            soz_pred, hemi_pred = model(eeg_data)

            batch_size = eeg_data.size(0)
            hemisphere_labels = torch.randint(0, 2, (batch_size,))

            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels)
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            val_loss += total_loss.item()

            all_soz_preds.append(soz_pred)
            all_soz_labels.append(soz_labels)
            all_hemi_preds.append(hemi_pred.argmax(dim=1))
            all_hemi_labels.append(hemisphere_labels)

    val_loss /= len(val_loader)

    # caculate auc-soz
    all_soz_preds = torch.cat(all_soz_preds).cpu().numpy()
    all_soz_labels = torch.cat(all_soz_labels).cpu().numpy()

    # average for auc for every channel
    channel_aucs = []
    for ch in range(all_soz_preds.shape[1]):
        try:
            auc = roc_auc_score(all_soz_labels[:, ch], all_soz_preds[:, ch])
            channel_aucs.append(auc)
        except:
            channel_aucs.append(0.5)

    soz_auc = np.mean(channel_aucs)

    # accuracy for hemi
    all_hemi_preds = torch.cat(all_hemi_preds).cpu().numpy()
    all_hemi_labels = torch.cat(all_hemi_labels).cpu().numpy()
    hemi_acc = accuracy_score(all_hemi_labels, all_hemi_preds)

    return val_loss, soz_auc, hemi_acc


def plot_training_history(history):
    """plotting training history"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))

    epochs = range(1, len(history['train_loss']) + 1)

    # loss graph
    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].set_title('Training and Validation Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # SOZ AUC curve
    axes[0, 1].plot(epochs, history['val_soz_auc'], 'g-', label='SOZ AUC')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('AUC')
    axes[0, 1].set_title('SOZ Prediction AUC')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].set_ylim([0.4, 1.0])

    # hemi accuracy
    axes[1, 0].plot(epochs, history['val_hemi_acc'], 'm-', label='Hemisphere Acc')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Accuracy')
    axes[1, 0].set_title('Hemisphere Classification Accuracy')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_ylim([0.4, 1.0])

    # LR curve
    axes[1, 1].axis('off')

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
    plt.show()

    # loss graph
    plt.figure(figsize=(8, 5))
    plt.plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-', linewidth=2, label='Val Loss')
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title('Loss Curve', fontsize=14)
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    plt.savefig('loss_curve.png', dpi=150, bbox_inches='tight')
    plt.show()


if __name__ == "__main__":
    print("=== quick test ===")
    model = quick_test_model()

    print("\n=== get data loader ===")
    train_loader, val_loader = get_dataloaders()

    print("\n=== starts training ===")
    print(f"training batch: {len(train_loader)}")
    print(f"validate batch: {len(val_loader)}")

    trained_model, history = train_model(
        model,
        train_loader,
        val_loader,
        epochs=10,
        learning_rate=1e-3
    )

    print("\n=== training history curve ===")
    plot_training_history(history)

    # save model
    torch.save(trained_model.state_dict(), 'eegnet_soz_model.pth')
    print("model has been saved as 'eegnet_soz_model.pth'")
