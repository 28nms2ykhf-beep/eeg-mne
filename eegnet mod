"""this is an EEGnet modification in terms to suit
    out task----predicting the seizure onset zone for
    focal epilepsy patients.
    we will make few modifications:
An EEGNet PyTorch version optimized for SOZ localization

Main modifications (optimized for your task):

1. Output layer: Changed to multi-label output (one SOZ probability per channel)

2. Feature dimensions: Adjusted according to your data (18 channels, 768 time points)

3. Added auxiliary task: Left and right brain classification to help learn spatial features

4. Added attention mechanism: Better focus on important channels and time points

5. Adjusted convolutional kernel size: Adapted to your sampling rate (typically 200Hz)"""


import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.nn import AvgPool2d

"""this model is to check the quailty oif the dataset
we are trying to have 100 smaples in each batch for training,
goal1. see if the loss decrease
we can probabaly check the overfitting later

task 1: load the data--sklearn,
randomly selected 10000 from the datasets
task 2: optimise some of the hyper parameters 
we to make the model adapt the task better"""

class EEGNetSOZ(nn.Module):
    def __init__(self, nb_classes=2, Chans=18, Samples=4096,
                 dropoutRate=0.3, kernLength=128, F1=8, D=2, F2=16,
                 dropoutType='Dropout', soz_channels=18):
        super(EEGNetSOZ, self).__init__()

        self.Chans = Chans
        self.Samples = Samples
        self.soz_channels = soz_channels

        # Block 1
        self.conv1_short = nn.Conv2d(1, F1 // 2, (1, 64), padding=(0, 32))  # fast wave
        self.conv1_long = nn.Conv2d(1, F1 // 2, (1, 256), padding=(0, 128))  # slow wave
        self.conv1_merge = nn.Conv2d(F1, F1, (1, 1))
        self.batchnorm1 = nn.BatchNorm2d(F1)

        # Block 2
        self.depthwise = nn.Conv2d(
            F1, F1 * D, (Chans, 1),
            groups=F1,
            bias=False
        )
        self.batchnorm2 = nn.BatchNorm2d(F1 * D)
        self.activation1 = nn.ELU()
        self.pool1 = nn.Sequential(AvgPool2d(1, 2),
                                   nn.Conv2d(F1 * D, F1 * D, (1, 3), stride=(1, 2), padding=(0, 1)))

        self.freq_attention = FrequencyAttention(F1 * D)

        # Dropout
        if dropoutType == 'SpatialDropout2D':
            self.dropout1 = nn.Dropout2d(dropoutRate)
        else:
            self.dropout1 = nn.Dropout(dropoutRate)

        # Block 3
        self.separable_depthwise = nn.Conv2d(
            F1 * D, F1 * D, (1, 16),
            padding=(0, 8),
            groups=F1 * D,
            bias=False
        )
        self.separable_pointwise = nn.Conv2d(
            F1 * D, F2, (1, 1),
            bias=False
        )
        self.batchnorm3 = nn.BatchNorm2d(F2)
        self.activation2 = nn.ELU()

        self.pool2 = nn.Sequential(MaxPool2d(1, 2),
                                   nn.Dropout2d(0.3)
                                   )

        self.dropout2 = nn.Dropout(dropoutRate)

        self._calculate_flatten_dim()


        self.hemisphere_head = nn.Sequential(
            nn.Linear(self.flatten_dim, 64),
            nn.ELU(),
            nn.Linear(64, 2)
        )

        self.feature_extractor = nn.Sequential(
            self.conv1, self.batchnorm1,
            self.depthwise, self.batchnorm2, self.activation1,
            self.pool1, self.dropout1,
            self.separable_depthwise, self.separable_pointwise,
            self.batchnorm3, self.activation2,
            self.pool2, self.dropout2
        )

        self.time_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, None)),
            nn.Conv1d(F2, F2 // 4, 1),
            nn.ReLU(),
            nn.Conv1d(F2 // 4, F2, 1),
            nn.Sigmoid()
        )

        self._initialize_weights()

    def _calculate_flatten_dim(self):
        with torch.no_grad():
            x = torch.randn(1, 1, self.Chans, self.Samples)

            # Block 1
            x = self.conv1(x)
            x = self.pool1(x)
            x = self.pool2(x)

            self.flatten_dim = x.numel()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='elu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x, return_features=False):
        if x.dim() == 3:
            x = x.unsqueeze(1)

        x = self.conv1(x)
        x = self.batchnorm1(x)

        x = self.depthwise(x)
        x = self.batchnorm2(x)
        x = self.activation1(x)

        x = self.pool1(x)
        x = self.dropout1(x)

        mid_features = x.clone() if return_features else None

        x = self.separable_depthwise(x)
        x = self.separable_pointwise(x)
        x = self.batchnorm3(x)
        x = self.activation2(x)

        if hasattr(self, 'time_attention'):
            attention_weights = self.time_attention(x)
            x = x * attention_weights

        x = self.pool2(x)
        x = self.dropout2(x)

        x = x.view(x.size(0), -1)

        soz_pred = self.soz_head(x)
        hemisphere_pred = self.hemisphere_head(x)

        if return_features:
            return soz_pred, hemisphere_pred, mid_features
        else:
            return soz_pred, hemisphere_pred

    def get_channel_importance(self, dataloader, device='cuda'):
        self.eval()
        all_importances = []

        with torch.no_grad():
            for batch in dataloader:
                if isinstance(batch, (list, tuple)):
                    eeg = batch[0]
                else:
                    eeg = batch

                eeg = eeg.to(device)

                eeg.requires_grad = True
                soz_pred, _ = self(eeg)

                channel_importances = []
                for ch in range(self.soz_channels):
                    grad_output = torch.zeros_like(soz_pred)
                    grad_output[:, ch] = 1.0

                    soz_pred.backward(grad_output, retain_graph=True)

                    importance = eeg.grad.abs().mean(dim=(0, 1, 2, 3))
                    channel_importances.append(importance.item())

                    self.zero_grad()
                    if eeg.grad is not None:
                        eeg.grad.zero_()

                all_importances.append(channel_importances)

        avg_importance = np.mean(all_importances, axis=0)
        return avg_importance


class SOZHead(nn.Module):
    def __init__(self, input_dim, num_channels):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, num_channels)

        self.channel_interaction = nn.Parameter(torch.eye(num_channels) * 0.1)

        self.elu = nn.ELU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        residual = x

        x = self.elu(self.fc1(x))
        x = self.dropout(x)
        x = self.elu(self.fc2(x))
        x = self.dropout(x)

        x = x + residual[:, :128]

        soz_logits = self.fc3(x)

        soz_logits = soz_logits @ self.channel_interaction

        return torch.sigmoid(soz_logits)


class LaplacianRegularization(nn.Module):
    def __init__(self, num_channels):
        super().__init__()
        self.laplacian = self._build_laplacian(num_channels)

    def forward(self, space_filters):
        reg_loss = torch.norm(self.laplacian @ spatial_filters, p=2)
        return reg_loss * 0.01


class FrequencyAttention(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.freq_pool = nn.AdaptiveAvgPool2d((None, 1))
        self.attention = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 8, 1),
            nn.ReLU(),
            nn.Conv2d(in_channels // 8, in_channels, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        # x: [B, C, 1, T]
        freq_weights = self.freq_pool(x)  # [B, C, 1, 1]
        freq_weights = self.attention(freq_weights)
        return x * freq_weights


class AdaptiveNormalization(nn.Module):
    def __init__(self, num_channels):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(1, 1, num_channels, 1))
        self.beta = nn.Parameter(torch.zeros(1, 1, num_channels, 1))

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)
        std = x.std(dim=-1, keepdim=True) + 1e-5
        x_normalized = (x - mean) / std

        return x_normalized * self.gamma + self.beta


self.norm = AdaptiveNormalization(Chans)
class MultiTaskLoss(nn.Module):
    def __init__(self, soz_weight=1.0, aux_weight=0.3, pos_weight=None):
        super().__init__()
        self.soz_weight = soz_weight
        self.aux_weight = aux_weight

        if pos_weight is not None:
            self.soz_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
        else:
            self.soz_criterion = nn.BCELoss()

        self.aux_criterion = nn.CrossEntropyLoss()

    def forward(self, soz_pred, soz_target, aux_pred=None, aux_target=None):
        soz_loss = self.soz_criterion(soz_pred, soz_target)

        aux_loss = 0
        if aux_pred is not None and aux_target is not None:
            aux_loss = self.aux_criterion(aux_pred, aux_target)

        total_loss = self.soz_weight * soz_loss + self.aux_weight * aux_loss

        return total_loss, soz_loss, aux_loss


class EEGDataProcessor:
    def __init__(self, sampling_rate=256, segment_length=16, num_channels=18):
        self.sampling_rate = sampling_rate
        self.segment_length = segment_length
        self.num_channels = num_channels
        self.total_samples = sampling_rate * segment_length  # 4096

    def load_pt_file(self, filepath):
        data = torch.load(filepath)
        eeg = data['eeg']
        labels = data['soz_labels']

        if eeg.shape[1] != self.total_samples:
            eeg = self._resample_or_pad(eeg)

        return eeg, labels

    def _resample_or_pad(self, eeg):
        current_length = eeg.shape[1]

        if current_length > self.total_samples:
            start = (current_length - self.total_samples) // 2
            eeg = eeg[:, start:start + self.total_samples]
        elif current_length < self.total_samples:
            padding = self.total_samples - current_length
            eeg = F.pad(eeg, (0, padding))

        return eeg

    def create_dataloader(self, pt_files, batch_size=32, shuffle=True):
        dataset = EEGDataset(pt_files, self)
        return torch.utils.data.DataLoader(
            dataset, batch_size=batch_size, shuffle=shuffle
        )


class EEGDataset(torch.utils.data.Dataset):
    def __init__(self, pt_files, processor):
        self.pt_files = pt_files
        self.processor = processor

    def __len__(self):
        return len(self.pt_files)

    def __getitem__(self, idx):
        eeg, soz_labels = self.processor.load_pt_file(self.pt_files[idx])

        left_channels = list(range(9))
        right_channels = list(range(9, 18))

        left_soz = soz_labels[left_channels].sum()
        right_soz = soz_labels[right_channels].sum()

        if left_soz > right_soz:
            hemisphere_label = torch.tensor([1, 0])
        elif right_soz > left_soz:
            hemisphere_label = torch.tensor([0, 1])
        else:
            hemisphere_label = torch.tensor([0.5, 0.5])

        return {
            'eeg': eeg,
            'soz_labels': soz_labels,
            'hemisphere_labels': hemisphere_label,
            'file_path': self.pt_files[idx]
        }



def train_eegnet_soz(config):
    processor = EEGDataProcessor(sampling_rate=256, segment_length=16, num_channels=18)

    import glob
    pt_files = glob.glob(f"{config['data_dir']}/*.pt")

    from sklearn.model_selection import train_test_split
    train_files, val_files = train_test_split(pt_files, test_size=0.2, random_state=42)

    train_loader = processor.create_dataloader(train_files, batch_size=config['batch_size'])
    val_loader = processor.create_dataloader(val_files, batch_size=config['batch_size'], shuffle=False)

    model = EEGNetSOZ(
        Chans=18,
        Samples=4096,
        kernLength=128,
        dropoutRate=0.3,
        soz_channels=18
    ).to(config['device'])

    pos_weight = torch.tensor([5.0]).to(config['device'])  # 根据你的数据调整
    criterion = MultiTaskLoss(soz_weight=1.0, aux_weight=0.2, pos_weight=pos_weight)

    optimizer = torch.optim.AdamW([
        {'params': model.feature_extractor.parameters(), 'lr': config['lr'] * 0.1},
        {'params': model.soz_head.parameters(), 'lr': config['lr']},
        {'params': model.hemisphere_head.parameters(), 'lr': config['lr']}
    ], weight_decay=1e-4)

    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )

    best_val_loss = float('inf')

    for epoch in range(config['epochs']):
        model.train()
        train_loss = 0

        for batch in train_loader:
            eeg = batch['eeg'].to(config['device'])
            soz_labels = batch['soz_labels'].to(config['device'])
            hemisphere_labels = batch['hemisphere_labels'].to(config['device'])

            soz_pred, hemisphere_pred = model(eeg)

            loss, soz_loss, aux_loss = criterion(
                soz_pred, soz_labels, hemisphere_pred, hemisphere_labels
            )

            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            train_loss += loss.item()

        model.eval()
        val_loss = 0
        val_auc = 0

        with torch.no_grad():
            for batch in val_loader:
                eeg = batch['eeg'].to(config['device'])
                soz_labels = batch['soz_labels'].to(config['device'])
                hemisphere_labels = batch['hemisphere_labels'].to(config['device'])

                soz_pred, hemisphere_pred = model(eeg)
                loss, _, _ = criterion(soz_pred, soz_labels, hemisphere_pred, hemisphere_labels)
                val_loss += loss.item()


        train_loss /= len(train_loader)
        val_loss /= len(val_loader)

        scheduler.step(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
            }, 'best_model.pth')

        print(f"Epoch {epoch + 1}/{config['epochs']}: "
              f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

    return model



def quick_test_model():
    batch_size = 4
    test_input = torch.randn(batch_size, 1, 18, 4096)
    model = EEGNetSOZ(Chans=18, Samples=4096)

    soz_pred, hemisphere_pred = model(test_input)

    print(f"input shape: {test_input.shape}")
    print(f"SOZ pred shape: {soz_pred.shape}")
    print(f"left right hemisphere: {hemisphere_pred.shape}")

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"total parameters: {total_params:,}")
    print(f"trainable parameters: {trainable_params:,}")

    return model


if __name__ == "__main__":
    print("quick test model")
    model = quick_test_model()

    print("\n=== model structure ===")
    print(model)
