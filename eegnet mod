"""this is an EEGnet modification in terms to suit
    out task----predicting the seizure onset zone for
    focal epilepsy patients.
    we will make few modifications:
An EEGNet PyTorch version optimized for SOZ localization

Main modifications (optimized for your task):

1. Output layer: Changed to multi-label output (one SOZ probability per channel)

2. Feature dimensions: Adjusted according to your data (18 channels, 768 time points)

3. Added auxiliary task: Left and right brain classification to help learn spatial features

4. Added attention mechanism: Better focus on important channels and time points

5. Adjusted convolutional kernel size: Adapted to your sampling rate (typically 200Hz)"""

import os
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, accuracy_score


class SimpleEEGDataset(Dataset):
    def __init__(self, files):
        self.files = files
        # according bipolar_pairs to define right hemisphere（18 channels）
        # left brain: 0-3, 8-11 (8)
        # right brain: 4-7, 12-15 (8)
        # midline: 16-17 (2)
        self.channel_hemispheres = torch.tensor([
            0, 0, 0, 0,  # 0-3: left temporal chain
            1, 1, 1, 1,  # 4-7: right temporal chain
            0, 0, 0, 0,  # 8-11: left parasagittal
            1, 1, 1, 1,  # 12-15: right parasagittal
            2, 2  # 16-17: midline
        ])

    def _get_hemisphere_pseudo_label(self, soz_labels):
        """determine hemisphere based on soz label"""
        left_mask = self.channel_hemispheres == 0
        right_mask = self.channel_hemispheres == 1

        left_soz = torch.sum(soz_labels[left_mask]).item()
        right_soz = torch.sum(soz_labels[right_mask]).item()

        if left_soz + right_soz > 0:
            return 0 if left_soz >= right_soz else 1
        else:
            return 0 if random.random() < 0.55 else 1

    def __getitem__(self, idx):
        data = torch.load(self.files[idx])
        eeg = data['eeg'].float().unsqueeze(0)

        # make sure its 18 channels
        if 'soz_labels' in data:
            soz_labels = data['soz_labels'].float()
            if soz_labels.dim() == 0:
                soz_labels = torch.zeros(18)
            elif soz_labels.shape[0] != 18:
                soz_labels = torch.zeros(18)
        else:
            soz_labels = torch.zeros(18)

        # find hemisphere label
        hemisphere_label = self._get_hemisphere_pseudo_label(soz_labels)

        return eeg, soz_labels, hemisphere_label


def get_dataloaders():
    data_root = "/home/sv25/desktop/eeg_epochs_output"
    all_pt_files = []

    if not os.path.exists(data_root):
        print(f"path error: {data_root}")
        return None, None

    for patient_id in os.listdir(data_root):
        patient_path = os.path.join(data_root, patient_id)
        if not os.path.isdir(patient_path):
            continue

        for session_dir in os.listdir(patient_path):
            session_path = os.path.join(patient_path, session_dir)
            if not os.path.isdir(session_path):
                continue

            for file_name in os.listdir(session_path):
                if file_name.endswith('.pt'):
                    file_path = os.path.join(session_path, file_name)
                    all_pt_files.append(file_path)

    print(f": {len(all_pt_files)} files has been found")

    if len(all_pt_files) == 0:
        print("error, no .pt files")
        return None, None

    max_files = min(10000, len(all_pt_files))
    if len(all_pt_files) > max_files:
        selected_files = random.sample(all_pt_files, max_files)
    else:
        selected_files = all_pt_files
        print(f"warning: only {len(all_pt_files)} files are selected")

    random.shuffle(selected_files)
    split_idx = int(0.8 * len(selected_files))
    train_files = selected_files[:split_idx]
    val_files = selected_files[split_idx:]

    print(f"training samples: {len(train_files)}")
    print(f"validation samples: {len(val_files)}")

    # dataloader
    train_loader = DataLoader(SimpleEEGDataset(train_files), batch_size=100, shuffle=True, num_workers=2)
    val_loader = DataLoader(SimpleEEGDataset(val_files), batch_size=100, shuffle=False, num_workers=2)

    return train_loader, val_loader


class SOZHead(nn.Module):
    def __init__(self, input_dim, num_channels):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, num_channels)

        self.channel_interaction = nn.Parameter(torch.eye(num_channels) * 0.1)
        self.elu = nn.ELU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        residual = x

        x = self.elu(self.fc1(x))
        x = self.dropout(x)
        x = self.elu(self.fc2(x))
        x = self.dropout(x)

        if residual.shape[1] >= 128:
            x = x + residual[:, :128]
        else:
            x = x + residual

        soz_logits = self.fc3(x)
        soz_logits = soz_logits @ self.channel_interaction

        return torch.sigmoid(soz_logits)


class FrequencyAttention(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.freq_pool = nn.AdaptiveAvgPool2d((None, 1))
        self.attention = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 8, 1),
            nn.ELU(),
            nn.Conv2d(in_channels // 8, in_channels, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        freq_weights = self.freq_pool(x)
        freq_weights = self.attention(freq_weights)
        return x * freq_weights


class AdaptiveNormalization(nn.Module):
    def __init__(self, num_channels):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(1, 1, num_channels, 1))
        self.beta = nn.Parameter(torch.zeros(1, 1, num_channels, 1))

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)
        std = x.std(dim=-1, keepdim=True) + 1e-5
        x_normalized = (x - mean) / std
        return x_normalized * self.gamma + self.beta


class EEGNetSOZ(nn.Module):
    def __init__(self, nb_classes=2, Chans=18, Samples=4096,
                 dropoutRate=0.3, kernLength=128, F1=8, D=2, F2=16,
                 dropoutType='Dropout', soz_channels=18):
        super(EEGNetSOZ, self).__init__()

        self.Chans = Chans
        self.Samples = Samples
        self.soz_channels = soz_channels
        self.F1 = F1
        self.D = D
        self.F2 = F2

        # multi size kernel
        self.conv1_short = nn.Conv2d(1, F1 // 2, (1, 64), padding=(0, 32))
        self.conv1_long = nn.Conv2d(1, F1 // 2, (1, 256), padding=(0, 128))
        self.conv1_merge = nn.Conv2d(F1, F1, (1, 1))
        self.batchnorm1 = nn.BatchNorm2d(F1)

        # spatial filter
        self.depthwise = nn.Conv2d(
            F1, F1 * D, (Chans, 1),
            groups=F1,
            bias=False
        )
        self.batchnorm2 = nn.BatchNorm2d(F1 * D)
        self.activation1 = nn.ELU()

        # pooling
        self.pool1 = nn.Sequential(
            nn.AvgPool2d((1, 2)),
            nn.Conv2d(F1 * D, F1 * D, (1, 3), stride=(1, 2), padding=(0, 1))
        )

        # freq attention
        self.freq_attention = FrequencyAttention(F1 * D)

        if dropoutType == 'SpatialDropout2D':
            self.dropout1 = nn.Dropout2d(dropoutRate)
        else:
            self.dropout1 = nn.Dropout(dropoutRate)

        # separable depthwise convolution
        self.separable_depthwise = nn.Conv2d(
            F1 * D, F1 * D, (1, 16),
            padding=(0, 8),
            groups=F1 * D,
            bias=False
        )
        self.separable_pointwise = nn.Conv2d(
            F1 * D, F2, (1, 1),
            bias=False
        )
        self.batchnorm3 = nn.BatchNorm2d(F2)
        self.activation2 = nn.ELU()

        # pooling2
        self.pool2 = nn.Sequential(
            nn.MaxPool2d((1, 4)),
            nn.Dropout2d(0.3)
        )
        self.dropout2 = nn.Dropout(dropoutRate)

        self.time_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, None)),
            nn.Conv2d(F2, F2 // 4, 1),
            nn.ELU(),
            nn.Conv2d(F2 // 4, F2, 1),
            nn.Sigmoid()
        )

        self.adaptive_norm = AdaptiveNormalization(Chans)
        self._calculate_flatten_dim()
        self.soz_head = SOZHead(self.flatten_dim, soz_channels)

        self.hemisphere_head = nn.Sequential(
            nn.Linear(self.flatten_dim, 64),
            nn.ELU(),
            nn.Linear(64, 2)
        )

        self._initialize_weights()

    def _calculate_flatten_dim(self):
        with torch.no_grad():
            x = torch.randn(1, 1, self.Chans, self.Samples)

            x_short = self.conv1_short(x)
            x_long = self.conv1_long(x)
            x = torch.cat([x_short, x_long], dim=1)
            x = self.conv1_merge(x)

            x = self.depthwise(x)
            x = self.pool1[0](x)
            x = self.pool1[1](x)

            x = self.separable_depthwise(x)
            x = self.separable_pointwise(x)
            x = self.pool2[0](x)

            self.flatten_dim = x.numel()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x, return_features=False):
        if x.dim() == 3:
            x = x.unsqueeze(1)

        x = self.adaptive_norm(x)

        x_short = self.conv1_short(x)
        x_long = self.conv1_long(x)
        x = torch.cat([x_short, x_long], dim=1)
        x = self.conv1_merge(x)
        x = self.batchnorm1(x)

        x = self.depthwise(x)
        x = self.batchnorm2(x)
        x = self.activation1(x)

        x = self.pool1(x)
        x = self.freq_attention(x)
        x = self.dropout1(x)

        mid_features = x.clone() if return_features else None

        x = self.separable_depthwise(x)
        x = self.separable_pointwise(x)
        x = self.batchnorm3(x)
        x = self.activation2(x)

        attention_weights = self.time_attention(x)
        x = x * attention_weights

        x = self.pool2(x)
        x = self.dropout2(x)

        x = x.view(x.size(0), -1)

        soz_pred = self.soz_head(x)
        hemisphere_pred = self.hemisphere_head(x)

        if return_features:
            return soz_pred, hemisphere_pred, mid_features
        else:
            return soz_pred, hemisphere_pred


def quick_test_model():
    """quick model structure test"""
    batch_size = 4
    test_input = torch.randn(batch_size, 1, 18, 4096)
    model = EEGNetSOZ(Chans=18, Samples=4096)

    soz_pred, hemisphere_pred = model(test_input)

    print(f"input shape: {test_input.shape}")
    print(f"SOZ prediction shape: {soz_pred.shape}")
    print(f"hemisphere prediction shaape: {hemisphere_pred.shape}")

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"total parameters: {total_params:,}")
    print(f"trainable parameters: {trainable_params:,}")

    return model


def train_model(model, train_loader, val_loader, epochs=10, learning_rate=1e-3):
    """training model"""
    criterion_soz = nn.BCELoss()
    criterion_hemi = nn.CrossEntropyLoss()

    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    history = {
        'train_loss': [],
        'val_loss': [],
        'train_soz_auc': [],
        'val_soz_auc': [],
        'train_hemi_acc': [],
        'val_hemi_acc': []
    }

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    print(f"device: {device}")

    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        train_soz_preds = []
        train_soz_labels = []
        train_hemi_preds = []
        train_hemi_labels = []

        for batch_idx, (eeg_data, soz_labels, hemisphere_labels) in enumerate(train_loader):
            eeg_data = eeg_data.to(device)
            soz_labels = soz_labels.to(device)
            hemisphere_labels = hemisphere_labels.to(device)

            optimizer.zero_grad()

            soz_pred, hemi_pred = model(eeg_data)

            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels)
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            train_loss += total_loss.item()
            train_soz_preds.append(soz_pred.detach().cpu())
            train_soz_labels.append(soz_labels.detach().cpu())
            train_hemi_preds.append(hemi_pred.detach().argmax(dim=1).cpu())
            train_hemi_labels.append(hemisphere_labels.detach().cpu())

            if batch_idx % 10 == 0:
                print(
                    f'Epoch {epoch + 1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | Loss: {total_loss.item():.4f}')

        train_loss /= len(train_loader)
        train_soz_preds = torch.cat(train_soz_preds)
        train_soz_labels = torch.cat(train_soz_labels)
        train_hemi_preds = torch.cat(train_hemi_preds)
        train_hemi_labels = torch.cat(train_hemi_labels)

        # validation
        val_loss, val_soz_auc, val_hemi_acc = validate_model(model, val_loader, criterion_soz, criterion_hemi, device)

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_soz_auc'].append(val_soz_auc)
        history['val_hemi_acc'].append(val_hemi_acc)

        scheduler.step()

        print(f'\nEpoch {epoch + 1}/{epochs}:')
        print(f'train loss: {train_loss:.4f}')
        print(f'validate loss: {val_loss:.4f}')
        print(f'validate SOZ AUC: {val_soz_auc:.4f}')
        print(f'validation hemisphere prediction accuracy: {val_hemi_acc:.4f}')
        print('-' * 50)

    return model, history


def validate_model(model, val_loader, criterion_soz, criterion_hemi, device):
    """model validation"""
    model.eval()
    val_loss = 0.0
    all_soz_preds = []
    all_soz_labels = []
    all_hemi_preds = []
    all_hemi_labels = []

    with torch.no_grad():
        for eeg_data, soz_labels, hemisphere_labels in val_loader:  
            eeg_data = eeg_data.to(device)
            soz_labels = soz_labels.to(device)
            hemisphere_labels = hemisphere_labels.to(device)

            soz_pred, hemi_pred = model(eeg_data)

            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels)
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            val_loss += total_loss.item()

            all_soz_preds.append(soz_pred.cpu())
            all_soz_labels.append(soz_labels.cpu())
            all_hemi_preds.append(hemi_pred.argmax(dim=1).cpu())
            all_hemi_labels.append(hemisphere_labels.cpu())

    val_loss /= len(val_loader)

    # caculate SOZ AUC
    all_soz_preds = torch.cat(all_soz_preds).numpy()
    all_soz_labels = torch.cat(all_soz_labels).numpy()

    channel_aucs = []
    for ch in range(all_soz_preds.shape[1]):
        try:
            auc = roc_auc_score(all_soz_labels[:, ch], all_soz_preds[:, ch])
            channel_aucs.append(auc)
        except:
            channel_aucs.append(0.5)

    soz_auc = np.mean(channel_aucs)

    # caculate hemisphere prediction accuracy
    all_hemi_preds = torch.cat(all_hemi_preds).numpy()
    all_hemi_labels = torch.cat(all_hemi_labels).numpy()
    hemi_acc = accuracy_score(all_hemi_labels, all_hemi_preds)

    return val_loss, soz_auc, hemi_acc


def plot_training_history(history):
    """plotting training history"""
    epochs = range(1, len(history['train_loss']) + 1)

    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 2)
    plt.plot(epochs, history['val_soz_auc'], 'g-', label='SOZ AUC')
    plt.xlabel('Epoch')
    plt.ylabel('AUC')
    plt.title('SOZ Prediction AUC')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim([0.4, 1.0])

    plt.subplot(1, 3, 3)
    plt.plot(epochs, history['val_hemi_acc'], 'm-', label='Hemisphere Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Hemisphere Classification Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim([0.4, 1.0])

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
    plt.show()


def predict_soz_and_hemisphere(model, eeg_input, threshold=0.5):
    """predict SOZ channel and hemisphere"""
    model.eval()
    device = next(model.parameters()).device

    with torch.no_grad():
        if eeg_input.dim() == 3:
            eeg_input = eeg_input.unsqueeze(0)
        eeg_input = eeg_input.to(device)

        soz_pred, hemi_pred = model(eeg_input)

    soz_probs = soz_pred.squeeze().cpu().numpy()
    soz_channels = np.where(soz_probs > threshold)[0].tolist()

    hemisphere_probs = torch.softmax(hemi_pred, dim=1).squeeze().cpu().numpy()
    predicted_hemisphere = 0 if hemisphere_probs[0] > hemisphere_probs[1] else 1

    # channel in groups
    left_channels = [0, 1, 2, 3, 8, 9, 10, 11]
    right_channels = [4, 5, 6, 7, 12, 13, 14, 15]

    left_soz = [ch for ch in soz_channels if ch in left_channels]
    right_soz = [ch for ch in soz_channels if ch in right_channels]

    # dominant hemisphere
    if len(left_soz) > len(right_soz):
        dominant_hemisphere = "Left"
    elif len(right_soz) > len(left_soz):
        dominant_hemisphere = "Right"
    else:
        dominant_hemisphere = "Bilateral"

    # channel loc
    channel_names = [
        'Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1',  # 0-3
        'Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2',  # 4-7
        'Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1',  # 8-11
        'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2',  # 12-15
        'Fz-Cz', 'Cz-Pz'  # 16-17
    ]

    result = {
        'soz_channels': soz_channels,
        'soz_channel_names': [channel_names[ch] for ch in soz_channels],
        'soz_probabilities': soz_probs.tolist(),
        'predicted_hemisphere': 'Left' if predicted_hemisphere == 0 else 'Right',
        'hemisphere_probabilities': hemisphere_probs.tolist(),
        'left_soz_channels': left_soz,
        'right_soz_channels': right_soz,
        'dominant_hemisphere': dominant_hemisphere,
        'detailed_info': f"SOZ in{dominant_hemisphere}hemisphere，channel: {[channel_names[ch] for ch in soz_channels]}"
    }

    return result


if __name__ == "__main__":
    print("quick test for model")
    model = quick_test_model()

    print("\n obtained data loader")
    train_loader, val_loader = get_dataloaders()

    if train_loader is None or val_loader is None:
        print("failed to load data")
        exit(1)

    print("\n starts training")
    print(f"training batch: {len(train_loader)}")
    print(f"validation batch: {len(val_loader)}")

    trained_model, history = train_model(
        model,
        train_loader,
        val_loader,
        epochs=10,
        learning_rate=1e-3
    )

    print("\n plotting training history")
    plot_training_history(history)

    # save model
    torch.save(trained_model.state_dict(), 'eegnet_soz_model.pth')
    print("model saved as 'eegnet_soz_model.pth'")

    # prediction test after training
    print("\n test model after training")
    test_eeg = torch.randn(1, 1, 18, 4096)
    result = predict_soz_and_hemisphere(trained_model, test_eeg)
    print(f"prediction: {result['detailed_info']}")
    print(f"SOZ probability: {result['soz_probabilities']}")
    print(f"hemisphere probability: {result['hemisphere_probabilities']}")


