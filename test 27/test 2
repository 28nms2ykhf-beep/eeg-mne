"""this is an EEGnet modification in terms to suit
    out task----predicting the seizure onset zone for
    focal epilepsy patients.
    we will make few modifications:
An EEGNet PyTorch version optimized for SOZ localization

Main modifications (optimized for your task):

1. Output layer: Changed to multi-label output (one SOZ probability per channel)

2. Feature dimensions: Adjusted according to your data (18 channels, 768 time points)

3. Added auxiliary task: Left and right brain classification to help learn spatial features

4. Added attention mechanism: Better focus on important channels and time points

5. Adjusted convolutional kernel size: Adapted to your sampling rate (typically 200Hz)"""

import os
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, accuracy_score


PATIENT_SOZ_INFO = {
    'patient_150009930': {
        'hemisphere': 'right', 
        'soz_channels': [4, 5, 6, 7, 12, 13, 14, 15],  
        'dominant_channels': [5, 6, 13, 14],
        'description': 'right temporal'
    },
    'patient_150017287': {
        'hemisphere': 'left',   
        'soz_channels': [0, 1, 2, 3, 8, 9, 10, 11],  
        'dominant_channels': [0, 1, 8, 9],
        'description': 'left frontotemporal'  
    },
    'patient_150008470': {
        'hemisphere': 'left',
        'soz_channels': [0, 1, 2, 3, 8, 9, 10, 11],  
        'dominant_channels': [1, 2, 9, 10],
        'description': 'left temporal and subtemporal chains'    
    },
    'patient_150003791': {
        'hemisphere': 'left',
        'soz_channels': [0, 1, 2, 3, 8, 9, 10, 11],  
        'dominant_channels': [2, 3, 10, 11],  
        'description': 'left posterior quadrants' 
    },
    'patient_150005601': {
        'hemisphere': 'left',
        'soz_channels': [0, 1, 2, 3, 8, 9, 10, 11],  
        'dominant_channels': [0, 1, 2, 8, 9, 10],
        'description': 'left temporal'   
    }
}


class SimpleEEGDataset(Dataset):
    def __init__(self, files):
        self.files = files
        # according bipolar_pairs to define right hemisphere（18 channels）
        # left brain: 0-3, 8-11 (8)
        # right brain: 4-7, 12-15 (8)
        # midline: 16-17 (2)
        self.channel_names = [
            'Fp1-F7',   # 0: 
            'F7-T3',    # 1: 
            'T3-T5',    # 2: 
            'T5-O1',    # 3: 
            'Fp2-F8',   # 4: 
            'F8-T4',    # 5: 
            'T4-T6',    # 6: 
            'T6-O2',    # 7: 
            'Fp1-F3',   # 8:
            'F3-C3',    # 9: 
            'C3-P3',    # 10: 
            'P3-O1',    # 11: 
            'Fp2-F4',   # 12: 
            'F4-C4',    # 13: 
            'C4-P4',    # 14: 
            'P4-O2',    # 15: 
            'Fz-Cz',    # 16: 
            'Cz-Pz'     # 17: 
        ]

        self.channel_hemispheres = torch.tensor([
            0, 0, 0, 0,  # 0-3: left temporal chain
            1, 1, 1, 1,  # 4-7: right temporal chain
            0, 0, 0, 0,  # 8-11: left parasagittal
            1, 1, 1, 1,  # 12-15: right parasagittal
            2, 2  # 16-17: midline
        ])

        self.patient_ids = []
        for file_path in self.files:
            parts = file_path.split('/')
            patient_id = None
            for part in parts:
                if part.startswith('patient_'):
                    patient_id = part
                    break
            self.patient_ids.append(patient_id)

    def _get_ground_truth_labels(self, patient_id):
        has_ground_truth = patient_id in PATIENT_SOZ_INFO

        if has_ground_truth:
            info = PATIENT_SOZ_INFO[patient_id]
            soz_labels = torch.zeros(18)
            soz_labels[info["soz_channels"]] = 1.0
            hemisphere_label = 1.0 if info["hemisphere"] == "right" else 0.0 
            return soz_labels, hemisphere_label, info.get("description", "")
        else:
            soz_labels = torch.zeros(18)
            hemisphere_label = -1.0
            return soz_labels, hemisphere_label, "no_label"
    
    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        file_path = self.files[idx]
        patient_id = self.patient_ids[idx]
        
        try:
            eeg_data = torch.load(file_path, map_location='cpu')
    
            if isinstance(eeg_data, torch.Tensor):
                eeg = eeg_data.float()
            else:
                eeg = torch.randn(1, 18, 4096).float()
    

            if eeg.dim() == 2:  # [18, 4096]
                eeg = eeg.unsqueeze(0)  # [1, 18, 4096]
            elif eeg.dim() == 3:  # [n, 18, 4096]
                eeg = eeg[0:1]
            else:
                raise ValueError(f"Unexpected tensor shape: {eeg.shape}")
    
            if eeg.shape[1] != 18:
                raise ValueError(f"Expected 18 channels, got {eeg.shape[1]}")
    
            if eeg.shape[2] < 4096:
                raise ValueError(f"Expected at least 4096 time points, got {eeg.shape[2]}")
            elif eeg.shape[2] > 4096:
                eeg = eeg[:, :, :4096]
            
            soz_labels, hemisphere_label, description = self._get_ground_truth_labels(patient_id)
            
            return eeg, soz_labels, hemisphere_label, patient_id
            
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
            eeg = torch.randn(1, 18, 4096).float()
            soz_labels = torch.zeros(18)
            hemisphere_label = 0
            return eeg, soz_labels, hemisphere_label, "error"
        
 
    @staticmethod
    def get_dataloaders(max_samples=10000, batch_size=32, validation_split=0.2):
        data_root = "/home/sv25/Desktop/eeg_epochs_output"
        
        if not os.path.exists(data_root):
            print(f"path error: {data_root}")
            return None, None

        import glob
        search_pattern = os.path.join(data_root, "**/*.pt")
        all_pt_files = glob.glob(search_pattern, recursive=True)

        if not all_pt_files:
            print(f"no .pt file")
            return None, None

        print(f"found {len(all_pt_files)} .pt files")
        
        patient_files = {}
        for file_path in all_pt_files:
            parts = file_path.split('/')
            patient_id = None
            for part in parts:
                if part.startswith('patient_'):
                    patient_id = part
                    break
            
            if patient_id:
                if patient_id not in patient_files:
                    patient_files[patient_id] = []
                patient_files[patient_id].append(file_path)
        
        print(f"found {len(patient_files)} patients")
        
        all_patient_ids = list(patient_files.keys())
        random.shuffle(all_patient_ids)
        
        split_idx = int(len(all_patient_ids) * 0.8)
        train_patient_ids = all_patient_ids[:split_idx]
        validation_patient_ids = all_patient_ids[split_idx:]
        print(f"Total patients: {len(all_patient_ids)}")
        print(f"Train patients: {len(train_patient_ids)}")
        print(f"Validation patients: {len(validation_patient_ids)}")
        
        train_files = []
        for patient_id in train_patient_ids:
            patient_file_list = patient_files[patient_id]
            if len(patient_file_list) > max_samples // len(train_patient_ids):
                sample_size = max_samples // len(train_patient_ids)
                train_files.extend(random.sample(patient_file_list, min(sample_size, len(patient_file_list))))
            else:
                train_files.extend(patient_file_list)
        

        validation_files = []
        for patient_id in validation_patient_ids:
            if patient_id in patient_files:
                patient_file_list = patient_files[patient_id]
                num_val = int(len(patient_file_list) * validation_split)
                if num_val > 0:
                    validation_files.extend(random.sample(patient_file_list, num_val))
                else:
                    validation_files.extend(patient_file_list[:1])  
        

        if len(train_files) > max_samples:
            train_files = random.sample(train_files, max_samples)
        
        print(f"training set has: {len(train_files)} samples")
        print(f"validation set has: {len(validation_files)} samples")
        
   
        print("\nValidation set ground truth:")
        for patient_id in validation_patient_ids:
            if patient_id in PATIENT_SOZ_INFO:
                info = PATIENT_SOZ_INFO[patient_id]
                print(f"  {patient_id}: {info['hemisphere']} hemisphere, SOZ channels: {info['soz_channels']}")
                print(f"    SOZ channels: {info['soz_channels']}")
        
        train_dataset = SimpleEEGDataset(train_files)
        val_dataset = SimpleEEGDataset(validation_files)

        num_workers = min(4, os.cpu_count() // 2)  
        print(f"using {num_workers} workers")

        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,
            persistent_workers=True if num_workers > 0 else False
        )
    
        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True,
            persistent_workers=True if num_workers > 0 else False
        )
    
        return train_loader, val_loader



class SOZHead(nn.Module):
    def __init__(self, input_dim, num_channels):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 512)
        self.ln1 = nn.LayerNorm(512)
        self.fc2 = nn.Linear(512, 256)
        self.ln2 = nn.LayerNorm(256)
        self.fc3 = nn.Linear(256, num_channels)
        
        self.elu = nn.ELU()
        self.dropout = nn.Dropout(0.6) 

    def forward(self, x):
        x = self.elu(self.ln1(self.fc1(x)))
        x = self.dropout(x)
        x = self.elu(self.ln2(self.fc2(x)))
        x = self.dropout(x)
        
        soz_logits = self.fc3(x)
        return soz_logits


class FrequencyAttention(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.freq_pool = nn.AdaptiveAvgPool2d((None, 1))
        self.attention = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 8, 1),
            nn.ELU(),
            nn.Conv2d(in_channels // 8, in_channels, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        freq_weights = self.freq_pool(x)
        freq_weights = self.attention(freq_weights)
        return x * freq_weights


class AdaptiveNormalization(nn.Module):
    def __init__(self, num_channels):
        super().__init__()
        self.gamma = nn.Parameter(torch.ones(1, 1, num_channels, 1))
        self.beta = nn.Parameter(torch.zeros(1, 1, num_channels, 1))

    def forward(self, x):
        mean = x.mean(dim=-1, keepdim=True)
        std = x.std(dim=-1, keepdim=True) + 1e-5
        x_normalized = (x - mean) / std
        return x_normalized * self.gamma + self.beta


class EEGNetSOZ(nn.Module):
    def __init__(self, nb_classes=2, Chans=18, Samples=4096,
                 dropoutRate=0.3, kernLength=128, F1=8, D=2, F2=16,
                 dropoutType='Dropout', soz_channels=18):
        super(EEGNetSOZ, self).__init__()

        self.Chans = Chans
        self.Samples = Samples
        self.soz_channels = soz_channels
        self.F1 = F1
        self.D = D
        self.F2 = F2
        self.input_norm = nn.BatchNorm2d(1)

        # multi size kernel
        self.conv1_short = nn.Conv2d(1, F1 // 2, (1, 64), padding=(0, 32))
        self.conv1_long = nn.Conv2d(1, F1 // 2, (1, 256), padding=(0, 128))
        self.conv1_merge = nn.Conv2d(F1, F1, (1, 1))
        self.batchnorm1 = nn.BatchNorm2d(F1)

        # spatial filter
        self.depthwise = nn.Conv2d(
            F1, F1 * D, (Chans, 1),
            groups=F1,
            bias=False
        )
        self.batchnorm2 = nn.BatchNorm2d(F1 * D)
        self.activation1 = nn.ELU()

        # pooling
        self.pool1 = nn.Sequential(
            nn.AvgPool2d((1, 2)),
            nn.Conv2d(F1 * D, F1 * D, (1, 3), stride=(1, 2), padding=(0, 1))
        )

        # freq attention
        self.freq_attention = FrequencyAttention(F1 * D)

        if dropoutType == 'SpatialDropout2D':
            self.dropout1 = nn.Dropout2d(dropoutRate)
        else:
            self.dropout1 = nn.Dropout(dropoutRate)

        # separable depthwise convolution
        self.separable_depthwise = nn.Conv2d(
            F1 * D, F1 * D, (1, 16),
            padding=(0, 8),
            groups=F1 * D,
            bias=False
        )
        self.separable_pointwise = nn.Conv2d(
            F1 * D, F2, (1, 1),
            bias=False
        )
        self.batchnorm3 = nn.BatchNorm2d(F2)
        self.activation2 = nn.ELU()

        # pooling2
        self.pool2 = nn.Sequential(
            nn.MaxPool2d((1, 4)),
            nn.Dropout2d(0.3)
        )
        self.dropout2 = nn.Dropout(dropoutRate)

        self.time_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, None)),
            nn.Conv2d(F2, F2 // 4, 1),
            nn.ELU(),
            nn.Conv2d(F2 // 4, F2, 1),
            nn.Sigmoid()
        )

        self.adaptive_norm = AdaptiveNormalization(Chans)
        self._calculate_flatten_dim()
        self.soz_head = SOZHead(self.flatten_dim, soz_channels)

        self.hemisphere_head = nn.Sequential(
            nn.Linear(self.flatten_dim, 64),
            nn.ELU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

        self._initialize_weights()

    def _calculate_flatten_dim(self):
        with torch.no_grad():
            x = torch.randn(1, 1, self.Chans, self.Samples)

            x_short = self.conv1_short(x)
            x_long = self.conv1_long(x)
            x = torch.cat([x_short, x_long], dim=1)
            x = self.conv1_merge(x)

            x = self.depthwise(x)
            x = self.pool1[0](x)
            x = self.pool1[1](x)

            x = self.separable_depthwise(x)
            x = self.separable_pointwise(x)
            x = self.pool2[0](x)

            self.flatten_dim = x.numel()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x, return_features=False):
        if x.dim() == 3:
            x = x.unsqueeze(1)

        x = self.input_norm(x)
        x = self.adaptive_norm(x)

        x_short = self.conv1_short(x)
        x_long = self.conv1_long(x)
        x = torch.cat([x_short, x_long], dim=1)
        x = self.conv1_merge(x)
        x = self.batchnorm1(x)

        x = self.depthwise(x)
        x = self.batchnorm2(x)
        x = self.activation1(x)

        x = self.pool1(x)
        x = self.freq_attention(x)
        x = self.dropout1(x)

        mid_features = x.clone() if return_features else None

        x = self.separable_depthwise(x)
        x = self.separable_pointwise(x)
        x = self.batchnorm3(x)
        x = self.activation2(x)

        attention_weights = self.time_attention(x)
        x = x * attention_weights

        x = self.pool2(x)
        x = self.dropout2(x)

        x = x.view(x.size(0), -1)

        soz_logits = self.soz_head(x)
        hemisphere_prob = self.hemisphere_head(x)

        if return_features:
            return soz_logits, hemisphere_prob, mid_features
        else:
            return soz_logits, hemisphere_prob


def quick_test_model():
    """quick model structure test"""
    batch_size = 4
    test_input = torch.randn(batch_size, 1, 18, 4096)
    model = EEGNetSOZ(Chans=18, Samples=4096)

    soz_pred, hemisphere_pred = model(test_input)

    print(f"input shape: {test_input.shape}")
    print(f"SOZ prediction shape: {soz_pred.shape}")
    print(f"hemisphere prediction shaape: {hemisphere_pred.shape}")

    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"total parameters: {total_params:,}")
    print(f"trainable parameters: {trainable_params:,}")

    return model


def train_model(model, train_loader, val_loader, epochs=10, learning_rate=1e-4):
    criterion_soz = nn.BCEWithLogitsLoss(reduction='none')
    criterion_hemi = nn.BCEWithLogitsLoss()

    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)
  
    warmup_epochs = 2
    def warmup_scheduler(epoch):
        if epoch < warmup_epochs:
            return (epoch + 1) / warmup_epochs
        else:
            return 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (epochs - warmup_epochs)))
    
    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_scheduler)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    print(f"device: {device}")

    
    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        
        for batch_idx, (eeg_data, soz_labels, hemisphere_labels, patient_ids) in enumerate(train_loader):
            eeg_data = eeg_data[mask].to(device)
            soz_labels = soz_labels[mask].to(device)
            hemisphere_labels = hemisphere_labels[mask].to(device)
            
            has_soz_label_mask = (soz_labels.sum(dim=1) >= 0)
            has_hemi_label_mask = (hemisphere_labels >= 0)
            valid_mask = has_soz_label_mask & has_hemi_label_mask
            
            if valid_mask.sum() == 0:
                continue
                
            eeg_data_valid = eeg_data[valid_mask]
            soz_labels_valid = soz_labels[valid_mask]
            hemisphere_labels_valid = hemisphere_labels[valid_mask]

            if hemisphere_labels_valid.dim == 0:
                hemisphere_labels_valid = hemisphere_labels_valid.unsequeese(0)
            
            optimizer.zero_grad()

            soz_pred, hemi_pred = model(eeg_data)
            soz_labels_valid = soz_labels.clone()
            soz_labels_valid[soz_labels_valid < 0] = 0 


            if scaler:
                with torch.amp.autocast('cuda'):
                    soz_pred, hemi_pred = model(eeg_data)
                    loss_soz = criterion_soz(soz_pred, soz_labels_valid)
                    weight_mask = (soz_labels >= 0).float() 
                    loss_soz = (loss_soz * weight_mask).sum() / weight_mask.sum()
                    loss_soz = loss_soz.mean()
                    loss_hemi = criterion_hemi(hemi_pred.squeeze(), hemisphere_labels)
                    total_loss = 0.8 * loss_soz + 0.2 * loss_hemi

                scaler.scale(total_loss).backward()
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                soz_pred, hemi_pred = model(eeg_data)
                loss_soz = criterion_soz(soz_pred, soz_labels)
                print(hemi_pred.dtype,hemisphere_labels.unsqueeze(1).dtype)
                hemisphere_labels_float = hemisphere_labels.unsqueeze(1).float()
                loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels.float())
                print(loss_hemi)
                total_loss = 0.8 * loss_soz + 0.2 * loss_hemi
                total_loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
            
            train_loss += total_loss.item()

            if batch_idx % 10 == 0:
                print(f'Epoch {epoch + 1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | Loss: {total_loss.item():.4f}')

        train_loss /= len(train_loader)
        
# validate 
        val_loss, val_soz_auc, val_hemi_acc = validate_model(model, val_loader, criterion_soz, criterion_hemi, device)

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_soz_auc'].append(val_soz_auc)
        history['val_hemi_acc'].append(val_hemi_acc)

        scheduler.step()

        print(f'\nEpoch {epoch + 1}/{epochs}:')
        print(f'train loss: {train_loss:.4f}')
        print(f'validate loss: {val_loss:.4f}')
        print(f'validate SOZ AUC: {val_soz_auc:.4f}')
        print(f'validation hemisphere prediction accuracy: {val_hemi_acc:.4f}')
        print('-' * 50)

    return model, history


def validate_model(model, val_loader, criterion_soz, criterion_hemi, device):
    model.eval()
    val_loss = 0.0
    all_soz_preds = []
    all_soz_labels = []
    all_hemi_preds = []
    all_hemi_labels = []
    
    patient_results = {}
    valid_samples = 0  

    with torch.no_grad():
        for eeg_data, soz_labels, hemisphere_labels, patient_ids in val_loader:
            eeg_data = eeg_data.to(device)
            soz_labels = soz_labels.to(device)
            hemisphere_labels = hemisphere_labels.to(device)
            
            has_soz_label_mask= (soz_labels.sum(dim=1) >= 0) 
            if has_soz_label_mask.sum() == 0:
                continue
                
            eeg_data = eeg_data[has_soz_label_mask]
            soz_labels = soz_labels[has_soz_label_mask]
            hemisphere_labels = hemisphere_labels[has_soz_label_mask]
            
            soz_pred, hemi_pred = model(eeg_data)

            loss_soz = criterion_soz(soz_pred, soz_labels)
            loss_soz = loss_soz.mean()
            loss_hemi = criterion_hemi(hemi_pred, hemisphere_labels.unsqueeze(1).float())
            loss_hemi = loss_hemi.mean()
            total_loss = 0.7 * loss_soz + 0.3 * loss_hemi

            val_loss += total_loss.item()
            valid_samples += eeg_data.size(0)
            
            all_soz_preds.append(soz_pred.cpu())
            all_soz_labels.append(soz_labels.cpu())
            all_hemi_preds.append((hemi_pred.squeeze() > 0.5).float().cpu())
            all_hemi_labels.append(hemisphere_labels.cpu())

    if valid_samples > 0:
        val_loss /= (valid_samples / val_loader.batch_size)
    else:
        print("Warning: No labeled samples in validation set")
        return 0, 0.5, 0.5

 
    all_soz_preds = torch.cat(all_soz_preds).numpy()
    all_soz_labels = torch.cat(all_soz_labels).numpy()

    channel_aucs = []
    valid_channels = 0
    for ch in range(all_soz_preds.shape[1]):
        true_labels = all_soz_labels[:, ch]
        if np.sum(true_labels == 1) > 0 and np.sum(true_labels == 0) > 0:
            try:
                auc = roc_auc_score(true_labels, all_soz_preds[:, ch])
                channel_aucs.append(auc)
                valid_channels += 1
            except:
                continue

    if valid_channels > 0:
        soz_auc = np.mean(channel_aucs)
    else:
        soz_auc = 0.5
        print("Warning: No valid channels for AUC calculation")


    all_hemi_preds = np.concatenate([np.array(preds) for preds in all_hemi_preds])
    all_hemi_labels = np.concatenate([np.array(labels) for labels in all_hemi_labels])
    hemi_acc = accuracy_score(all_hemi_labels, all_hemi_preds)
    

    print("\nValidation results by patient:")
    print("-" * 60)
    for patient_id, results in patient_results.items():
        if patient_id in PATIENT_SOZ_INFO:
            info = PATIENT_SOZ_INFO[patient_id]
            

            if results['hemi_labels']:
                patient_hemi_acc = np.mean(np.array(results['hemi_preds']) == np.array(results['hemi_labels']))
            else:
                patient_hemi_acc = 0.0
            
            print(f"{patient_id}: {info['description']}")
            print(f"  Ground truth: {info['hemisphere']} hemisphere")
            print(f"  Hemisphere accuracy: {patient_hemi_acc:.4f}")
            print(f"  SOZ channels: {info['soz_channels']}")
    
    return val_loss, soz_auc, hemi_acc


def plot_training_history(history):
    epochs = range(1, len(history['train_loss']) + 1)

    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.plot(epochs, history['train_loss'], 'b-', label='Train Loss')
    plt.plot(epochs, history['val_loss'], 'r-', label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 2)
    plt.plot(epochs, history['val_soz_auc'], 'g-', label='SOZ AUC')
    plt.xlabel('Epoch')
    plt.ylabel('AUC')
    plt.title('SOZ Prediction AUC')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim([0.4, 1.0])

    plt.subplot(1, 3, 3)
    plt.plot(epochs, history['val_hemi_acc'], 'm-', label='Hemisphere Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Hemisphere Classification Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim([0.4, 1.0])

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
    plt.show()





def predict_soz_and_hemisphere(model, eeg_input, patient_id=None, threshold=0.5):
    model.eval()
    device = next(model.parameters()).device

    with torch.no_grad():
        if eeg_input.dim() == 3:
            eeg_input = eeg_input.unsqueeze(0)
        eeg_input = eeg_input.to(device)

        soz_pred, hemi_pred = model(eeg_input)

        soz_logits, hemi_logits = model(eeg_input)
        soz_probs = torch.sigmoid(soz_logits).squeeze().cpu().numpy()
        hemi_probs = torch.sigmoid(hemi_logits).squeeze().cpu().numpy()

    if patient_id and patient_id in PATIENT_SOZ_INFO: 
        info = PATIENT_SOZ_INFO[patient_id]
        print(f"\nPatient {patient_id} - Ground truth:")
        print(f"  Description: {info.get('description', 'N/A')}")
        print(f"  Hemisphere: {info['hemisphere']}")
        print(f"  SOZ channels: {info['soz_channels']}")
        print(f"  Predicted hemisphere: {'left' if predicted_hemisphere == 0 else 'right'}")

    left_channels = [0, 1, 2, 3, 8, 9, 10, 11]
    right_channels = [4, 5, 6, 7, 12, 13, 14, 15]

    left_soz = [ch for ch in soz_channels if ch in left_channels]
    right_soz = [ch for ch in soz_channels if ch in right_channels]

    if len(left_soz) > len(right_soz):
        dominant_hemisphere = "Left"
    elif len(right_soz) > len(left_soz):
        dominant_hemisphere = "Right"
    else:
        dominant_hemisphere = "Bilateral"

    channel_names = [
        'Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1',  # 0-3
        'Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2',  # 4-7
        'Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1',  # 8-11
        'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2',  # 12-15
        'Fz-Cz', 'Cz-Pz'  # 16-17
    ]

    result = {
        'patient_id': patient_id,
        'soz_channels': soz_channels,
        'soz_channel_names': [channel_names[ch] for ch in soz_channels],
        'soz_probabilities': soz_probs.tolist(),
        'predicted_hemisphere': 'Left' if predicted_hemisphere == 0 else 'Right',
        'hemisphere_probabilities': hemisphere_probs.tolist(),
        'left_soz_channels': left_soz,
        'right_soz_channels': right_soz,
        'dominant_hemisphere': dominant_hemisphere,
        'detailed_info': f"SOZ in {dominant_hemisphere} hemisphere, channels: {[channel_names[ch] for ch in soz_channels]}"
    }

    return result


if __name__ == "__main__":
    print("quick test for model")
    model = quick_test_model() 

    print("\nloading data...")
    train_loader, val_loader = SimpleEEGDataset.get_dataloaders(max_samples=10000, batch_size=64)

    if train_loader is None or val_loader is None:
        print("failed to load data")
        exit(1)

    print("\nstarting training...")
    print(f"training batches: {len(train_loader)}")
    print(f"validation batches: {len(val_loader)}")

    trained_model, history = train_model( 
        model,
        train_loader,
        val_loader,
        epochs=20,
        learning_rate=1e-4
    )

    print("\nplotting training history...")
    plot_training_history(history) 


    torch.save(trained_model.state_dict(), 'eegnet_soz_model.pth')
    print("model saved as 'eegnet_soz_model.pth'")


    print("\ntesting model after training...")
    test_eeg = torch.randn(1, 1, 18, 4096)
    result = predict_soz_and_hemisphere(trained_model, test_eeg) 
    print(f"prediction: {result['detailed_info']}")
    print(f"SOZ probabilities: {result['soz_probabilities']}")
    print(f"hemisphere probabilities: {result['hemisphere_probabilities']}")
